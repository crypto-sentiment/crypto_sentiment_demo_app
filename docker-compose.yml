version: '3.9'

services:
  crawler:
    image: basic_image_crawler
    build: crypto_sentiment_demo_app/crawler
    command: python3 -m crypto_sentiment_demo_app.crawler.crawler
    volumes:
      - ./:/root
    profiles:
      - production

  model_inference_api:
    image: basic_image_model_fast_api
    build: crypto_sentiment_demo_app/model_inference_api
    command: uvicorn crypto_sentiment_demo_app.model_inference_api.api.model:app --host model_inference_api --port 8001 --reload
    volumes:
      - ./:/root
    ports:
      - "8001:8001"
    hostname: model_inference_api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://model_inference_api:8001/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    profiles:
      - production
    networks:
      - model_inference

  model_scorer:
    image: basic_image_model_scorer
    build: crypto_sentiment_demo_app/model_scorer
    command: python3 -m crypto_sentiment_demo_app.model_scorer.model_scorer
    volumes:
      - ./:/root
    depends_on:
      model_inference_api:
        condition: service_healthy
    links:
      - model_inference_api
    profiles:
      - production
    networks:
      - model_inference

  frontend:
    image: react_frontend_image
    build: crypto_sentiment_demo_app/frontend
    hostname: frontend
    command: npm start
    ports:
      - "3000:3000"
    volumes:
      - ./:/root
    depends_on:
      model_inference_api:
        condition: service_healthy
    links:
      - model_inference_api
    profiles:
      - production
    networks:
      - model_inference


  train:
    image: basic_image_train
    build:
      context: crypto_sentiment_demo_app/train
      args:
        USER_ID: "$USER"
        GROUP_ID: "$GROUP"
      dockerfile: Dockerfile-cpu
    command: python3 crypto_sentiment_demo_app/train/train.py
    volumes:
      - ./:/root
    profiles:
      - train

networks:
  model_inference:
    driver: bridge
